# -*- coding: utf-8 -*-
"""Hw3_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11RS2Rsdvb2lD3cz70h8O0a1_lHh17bTf
"""

#Importing the libraries
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import time
import numpy as np
import torch.nn.functional as F

#Performing Random transformations on the images
transform_train = transforms.Compose([
    transforms.RandomCrop(32,padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor()
])

train_data= torchvision.datasets.CIFAR10(root='../../data/',train=True,
                                         transform=transform_train,download=True)
test_data = torchvision.datasets.CIFAR10(root='../../data/',train=False,
                                         transform=transforms.ToTensor(),download=True)

train_loader = torch.utils.data.DataLoader(dataset=train_data,batch_size=24,shuffle=True)

test_loader = torch.utils.data.DataLoader(dataset=test_data,batch_size=24,shuffle=False)

num_epochs = 50
learning_rate = 0.0001
scheduler_step_size = 10
scheduler_gamma = 0.1

class Convnet(nn.Module):
    def __init__(self):
        super(Convnet,self).__init__()
        self.conv1= nn.Conv2d(3,64,kernel_size=4, stride=1, padding=2)
        self.conv1_bn= nn.BatchNorm2d(64)
        
        self.conv2 = nn.Conv2d(64,64, kernel_size=4, stride=1, padding=2)
        self.conv2_pool = nn.MaxPool2d(kernel_size=2,stride=2)
        self.conv3 = nn.Conv2d(64,64, kernel_size=4, stride=1, padding=2)
        self.conv3_bn = nn.BatchNorm2d(64)
        self.conv4 = nn.Conv2d(64,64, kernel_size=4, stride=1, padding=2)
        self.conv4_drop = nn.Dropout()
        self.conv5 = nn.Conv2d(64,64, kernel_size=4, stride=1, padding=2)
        self.conv5_bn = nn.BatchNorm2d(64)
        self.conv6 = nn.Conv2d(64,64, kernel_size=3, stride=1, padding=0)
        self.conv6_pool = nn.MaxPool2d(kernel_size=2,stride=2)
        self.fc1 = nn.Linear(64*9*9,500)
        self.fc2 = nn.Linear(500,500)
        self.fc3 = nn.Linear(500,10)
        
    def forward(self,x):
        
      x = F.relu(self.conv1_bn(self.conv1(x)))
      x = self.conv2_pool(F.relu(self.conv2(x)))
      x = F.relu(self.conv3_bn(self.conv3(x)))
      x = self.conv4_drop(F.relu(self.conv4(x)))
      x = F.relu(self.conv5_bn(self.conv5(x)))
      x = self.conv6_pool(F.relu(self.conv6(x)))
      x = x.view(-1, 64 * 9 * 9)
      x = F.relu(self.fc1(x))
      x = F.relu(self.fc2(x))
      x = self.fc3(x)
      return x
    
net = Convnet()

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = Convnet().to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step_size,gamma=scheduler_gamma)
total_step= len(train_loader)
start_time= time.time()

store_test_acc = 0.0
for epoch in range(num_epochs):
  scheduler.step()
  correct=0
  total=0
  running_loss=0.0
  
  for images,labels in train_loader:
    #move tensors to the configured device
    images = images.to(device)
    labels = labels.to(device)
    #Forward pass
    outputs=model(images)
    loss = criterion(outputs,labels)
    _, predicted = torch.max(outputs.data,1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()
    
    #Backward and optimize
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    # print statistics
    running_loss += loss.item()

  # Normalizing the loss by the total number of train batches
  running_loss /= len(train_loader)
  train_accuracy = correct/total
  with torch.no_grad():
    correct = 0
    total = 0
    for images,labels in test_loader:
      images = images.to(device)
      labels = labels.to(device)
      outputs = model(images)
      _, predicted = torch.max(outputs.data,1)
      total += labels.size(0)
      correct += (predicted == labels).sum().item()
    test_accuracy = correct/total
    print('Epoch {}, Time {:.4f}, Loss {:.4f}, Train Accuracy: {:.4f}, Test Accuracy: {:.4f}'.format(epoch, time.time()-start_time,running_loss,train_accuracy,test_accuracy))
    
    if epoch > 29:
      store_test_acc = store_test_acc + test_accuracy
    torch.save(model.state_dict(), 'epoch-{}.cpkt'.format(epoch))
avg_test_acc = store_test_acc*100/20.0
print('Average Test Accuracy: ', avg_test_acc)

#heuristic prediction with one test accuracy
net.eval()
with torch.no_grad():
  correct = 0
  total = 0
  for images,labels in test_loader:
    images = images.to(device)
    labels = labels.to(device)
    outputs = model(images)
    _, predicted = torch.max(outputs.data,1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()
  test_accuracy = correct/total
print('Test Accuracy: ', test_accuracy)

